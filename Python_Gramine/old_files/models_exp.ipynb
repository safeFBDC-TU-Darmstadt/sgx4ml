{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d54e93b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/gagandeep/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f1d7a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n",
       "=====================================================================================================================================================================\n",
       "AlexNet                                  [1, 3, 227, 227]          [1, 1000]                 --                        --                        --\n",
       "├─Sequential: 1-1                        [1, 3, 227, 227]          [1, 256, 6, 6]            --                        --                        --\n",
       "│    └─Conv2d: 2-1                       [1, 3, 227, 227]          [1, 64, 56, 56]           23,296                    [11, 11]                  73,056,256\n",
       "│    └─ReLU: 2-2                         [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --                        --\n",
       "│    └─MaxPool2d: 2-3                    [1, 64, 56, 56]           [1, 64, 27, 27]           --                        3                         --\n",
       "│    └─Conv2d: 2-4                       [1, 64, 27, 27]           [1, 192, 27, 27]          307,392                   [5, 5]                    224,088,768\n",
       "│    └─ReLU: 2-5                         [1, 192, 27, 27]          [1, 192, 27, 27]          --                        --                        --\n",
       "│    └─MaxPool2d: 2-6                    [1, 192, 27, 27]          [1, 192, 13, 13]          --                        3                         --\n",
       "│    └─Conv2d: 2-7                       [1, 192, 13, 13]          [1, 384, 13, 13]          663,936                   [3, 3]                    112,205,184\n",
       "│    └─ReLU: 2-8                         [1, 384, 13, 13]          [1, 384, 13, 13]          --                        --                        --\n",
       "│    └─Conv2d: 2-9                       [1, 384, 13, 13]          [1, 256, 13, 13]          884,992                   [3, 3]                    149,563,648\n",
       "│    └─ReLU: 2-10                        [1, 256, 13, 13]          [1, 256, 13, 13]          --                        --                        --\n",
       "│    └─Conv2d: 2-11                      [1, 256, 13, 13]          [1, 256, 13, 13]          590,080                   [3, 3]                    99,723,520\n",
       "│    └─ReLU: 2-12                        [1, 256, 13, 13]          [1, 256, 13, 13]          --                        --                        --\n",
       "│    └─MaxPool2d: 2-13                   [1, 256, 13, 13]          [1, 256, 6, 6]            --                        3                         --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [1, 256, 6, 6]            [1, 256, 6, 6]            --                        --                        --\n",
       "├─Sequential: 1-3                        [1, 9216]                 [1, 1000]                 --                        --                        --\n",
       "│    └─Dropout: 2-14                     [1, 9216]                 [1, 9216]                 --                        --                        --\n",
       "│    └─Linear: 2-15                      [1, 9216]                 [1, 4096]                 37,752,832                --                        37,752,832\n",
       "│    └─ReLU: 2-16                        [1, 4096]                 [1, 4096]                 --                        --                        --\n",
       "│    └─Dropout: 2-17                     [1, 4096]                 [1, 4096]                 --                        --                        --\n",
       "│    └─Linear: 2-18                      [1, 4096]                 [1, 4096]                 16,781,312                --                        16,781,312\n",
       "│    └─ReLU: 2-19                        [1, 4096]                 [1, 4096]                 --                        --                        --\n",
       "│    └─Linear: 2-20                      [1, 4096]                 [1, 1000]                 4,097,000                 --                        4,097,000\n",
       "=====================================================================================================================================================================\n",
       "Total params: 61,100,840\n",
       "Trainable params: 61,100,840\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 717.27\n",
       "=====================================================================================================================================================================\n",
       "Input size (MB): 0.62\n",
       "Forward/backward pass size (MB): 4.01\n",
       "Params size (MB): 244.40\n",
       "Estimated Total Size (MB): 249.03\n",
       "====================================================================================================================================================================="
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(model, (3, 227, 227), batch_dim = 0, col_names = (\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"), verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7671297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used seed : 8754805328971744210\n",
      "TensorboardX summary writer created\n",
      "DataParallel(\n",
      "  (module): AlexNet(\n",
      "    (net): Sequential(\n",
      "      (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "      (1): ReLU()\n",
      "      (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (5): ReLU()\n",
      "      (6): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
      "      (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (9): ReLU()\n",
      "      (10): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU()\n",
      "      (12): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU()\n",
      "      (14): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Dropout(p=0.5, inplace=True)\n",
      "      (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.5, inplace=True)\n",
      "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "AlexNet created\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any class folder in alexnet_data_in/imagenet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 125\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlexNet created\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# create dataset and data loader\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mImageFolder(TRAIN_IMG_DIR, transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# transforms.RandomResizedCrop(IMAGE_DIM, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mCenterCrop(IMAGE_DIM),\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# transforms.RandomHorizontalFlip(),\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m    130\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m]),\n\u001b[1;32m    131\u001b[0m ]))\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset created\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    133\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m    134\u001b[0m     dataset,\n\u001b[1;32m    135\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    139\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE)\n",
      "File \u001b[0;32m~/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/datasets/folder.py:310\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    304\u001b[0m         root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m         is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m ):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImageFolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[0;32m~/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/datasets/folder.py:145\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    136\u001b[0m         root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m         is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    142\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28msuper\u001b[39m(DatasetFolder, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform,\n\u001b[1;32m    144\u001b[0m                                         target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[0;32m--> 145\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[0;32m~/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/datasets/folder.py:221\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/datasets/folder.py:42\u001b[0m, in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     40\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mscandir(directory) \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m class_to_idx \u001b[38;5;241m=\u001b[39m {cls_name: i \u001b[38;5;28;01mfor\u001b[39;00m i, cls_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(classes)}\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classes, class_to_idx\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in alexnet_data_in/imagenet."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implementation of AlexNet, from paper\n",
    "\"ImageNet Classification with Deep Convolutional Neural Networks\" by Alex Krizhevsky et al.\n",
    "\n",
    "See: https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# define pytorch device - useful for device-agnostic execution\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# define model parameters\n",
    "NUM_EPOCHS = 90  # original paper\n",
    "BATCH_SIZE = 128\n",
    "MOMENTUM = 0.9\n",
    "LR_DECAY = 0.0005\n",
    "LR_INIT = 0.01\n",
    "IMAGE_DIM = 227  # pixels\n",
    "NUM_CLASSES = 1000  # 1000 classes for imagenet 2012 dataset\n",
    "DEVICE_IDS = [0, 1, 2, 3]  # GPUs to use\n",
    "# modify this to point to your data directory\n",
    "INPUT_ROOT_DIR = 'alexnet_data_in'\n",
    "TRAIN_IMG_DIR = 'alexnet_data_in/imagenet'\n",
    "OUTPUT_DIR = 'alexnet_data_out'\n",
    "LOG_DIR = OUTPUT_DIR + '/tblogs'  # tensorboard logs\n",
    "CHECKPOINT_DIR = OUTPUT_DIR + '/models'  # model checkpoints\n",
    "\n",
    "# make checkpoint path directory\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network model consisting of layers propsed by AlexNet paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=1000):\n",
    "        \"\"\"\n",
    "        Define and allocate layers for this neural net.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): number of classes to predict with this model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # input size should be : (b x 3 x 227 x 227)\n",
    "        # The image in the original paper states that width and height are 224 pixels, but\n",
    "        # the dimensions after first convolution layer do not lead to 55 x 55.\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),  # (b x 96 x 55 x 55)\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  # section 3.3\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 96 x 27 x 27)\n",
    "            nn.Conv2d(96, 256, 5, padding=2),  # (b x 256 x 27 x 27)\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 13 x 13)\n",
    "            nn.Conv2d(256, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, padding=1),  # (b x 256 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 6 x 6)\n",
    "        )\n",
    "        # classifier is just a name for linear layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5, inplace=True),\n",
    "            nn.Linear(in_features=(256 * 6 * 6), out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5, inplace=True),\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=4096, out_features=num_classes),\n",
    "        )\n",
    "        self.init_bias()  # initialize bias\n",
    "\n",
    "    def init_bias(self):\n",
    "        for layer in self.net:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                nn.init.normal_(layer.weight, mean=0, std=0.01)\n",
    "                nn.init.constant_(layer.bias, 0)\n",
    "        # original paper = 1 for Conv2d layers 2nd, 4th, and 5th conv layers\n",
    "        nn.init.constant_(self.net[4].bias, 1)\n",
    "        nn.init.constant_(self.net[10].bias, 1)\n",
    "        nn.init.constant_(self.net[12].bias, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Pass the input through the net.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): input tensor\n",
    "\n",
    "        Returns:\n",
    "            output (Tensor): output tensor\n",
    "        \"\"\"\n",
    "        x = self.net(x)\n",
    "        x = x.view(-1, 256 * 6 * 6)  # reduce the dimensions for linear layer input\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # print the seed value\n",
    "    seed = torch.initial_seed()\n",
    "    print('Used seed : {}'.format(seed))\n",
    "\n",
    "    tbwriter = SummaryWriter(log_dir=LOG_DIR)\n",
    "    print('TensorboardX summary writer created')\n",
    "\n",
    "    # create model\n",
    "    alexnet = AlexNet(num_classes=NUM_CLASSES).to(device)\n",
    "    # train on multiple GPUs\n",
    "    alexnet = torch.nn.parallel.DataParallel(alexnet, device_ids=DEVICE_IDS)\n",
    "    print(alexnet)\n",
    "    print('AlexNet created')\n",
    "\n",
    "    # create dataset and data loader\n",
    "    dataset = datasets.ImageFolder(TRAIN_IMG_DIR, transforms.Compose([\n",
    "        # transforms.RandomResizedCrop(IMAGE_DIM, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
    "        transforms.CenterCrop(IMAGE_DIM),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]))\n",
    "    print('Dataset created')\n",
    "    dataloader = data.DataLoader(\n",
    "        dataset,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=8,\n",
    "        drop_last=True,\n",
    "        batch_size=BATCH_SIZE)\n",
    "    print('Dataloader created')\n",
    "\n",
    "    # create optimizer\n",
    "    # the one that WORKS\n",
    "    optimizer = optim.Adam(params=alexnet.parameters(), lr=0.0001)\n",
    "    ### BELOW is the setting proposed by the original paper - which doesn't train....\n",
    "    # optimizer = optim.SGD(\n",
    "    #     params=alexnet.parameters(),\n",
    "    #     lr=LR_INIT,\n",
    "    #     momentum=MOMENTUM,\n",
    "    #     weight_decay=LR_DECAY)\n",
    "    print('Optimizer created')\n",
    "\n",
    "    # multiply LR by 1 / 10 after every 30 epochs\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "    print('LR Scheduler created')\n",
    "\n",
    "    # start training!!\n",
    "    print('Starting training...')\n",
    "    total_steps = 1\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        lr_scheduler.step()\n",
    "        for imgs, classes in dataloader:\n",
    "            imgs, classes = imgs.to(device), classes.to(device)\n",
    "\n",
    "            # calculate the loss\n",
    "            output = alexnet(imgs)\n",
    "            loss = F.cross_entropy(output, classes)\n",
    "\n",
    "            # update the parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # log the information and add to tensorboard\n",
    "            if total_steps % 10 == 0:\n",
    "                with torch.no_grad():\n",
    "                    _, preds = torch.max(output, 1)\n",
    "                    accuracy = torch.sum(preds == classes)\n",
    "\n",
    "                    print('Epoch: {} \\tStep: {} \\tLoss: {:.4f} \\tAcc: {}'\n",
    "                        .format(epoch + 1, total_steps, loss.item(), accuracy.item()))\n",
    "                    tbwriter.add_scalar('loss', loss.item(), total_steps)\n",
    "                    tbwriter.add_scalar('accuracy', accuracy.item(), total_steps)\n",
    "\n",
    "            # print out gradient values and parameter average values\n",
    "            if total_steps % 100 == 0:\n",
    "                with torch.no_grad():\n",
    "                    # print and save the grad of the parameters\n",
    "                    # also print and save parameter values\n",
    "                    print('*' * 10)\n",
    "                    for name, parameter in alexnet.named_parameters():\n",
    "                        if parameter.grad is not None:\n",
    "                            avg_grad = torch.mean(parameter.grad)\n",
    "                            print('\\t{} - grad_avg: {}'.format(name, avg_grad))\n",
    "                            tbwriter.add_scalar('grad_avg/{}'.format(name), avg_grad.item(), total_steps)\n",
    "                            tbwriter.add_histogram('grad/{}'.format(name),\n",
    "                                    parameter.grad.cpu().numpy(), total_steps)\n",
    "                        if parameter.data is not None:\n",
    "                            avg_weight = torch.mean(parameter.data)\n",
    "                            print('\\t{} - param_avg: {}'.format(name, avg_weight))\n",
    "                            tbwriter.add_histogram('weight/{}'.format(name),\n",
    "                                    parameter.data.cpu().numpy(), total_steps)\n",
    "                            tbwriter.add_scalar('weight_avg/{}'.format(name), avg_weight.item(), total_steps)\n",
    "\n",
    "            total_steps += 1\n",
    "\n",
    "        # save checkpoints\n",
    "        checkpoint_path = os.path.join(CHECKPOINT_DIR, 'alexnet_states_e{}.pkl'.format(epoch + 1))\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'total_steps': total_steps,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'model': alexnet.state_dict(),\n",
    "            'seed': seed,\n",
    "        }\n",
    "        torch.save(state, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68de3eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network model consisting of layers propsed by AlexNet paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=1000):\n",
    "        \"\"\"\n",
    "        Define and allocate layers for this neural net.\n",
    "        Args:\n",
    "            num_classes (int): number of classes to predict with this model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # input size should be : (b x 3 x 227 x 227)\n",
    "        # The image in the original paper states that width and height are 224 pixels, but\n",
    "        # the dimensions after first convolution layer do not lead to 55 x 55.\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),  # (b x 96 x 55 x 55)\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  # section 3.3\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 96 x 27 x 27)\n",
    "            nn.Conv2d(96, 256, 5, padding=2),  # (b x 256 x 27 x 27)\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 13 x 13)\n",
    "            nn.Conv2d(256, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, padding=1),  # (b x 256 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 6 x 6)\n",
    "        )\n",
    "        # classifier is just a name for linear layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5, inplace=True),\n",
    "            nn.Linear(in_features=(256 * 6 * 6), out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5, inplace=True),\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=4096, out_features=num_classes),\n",
    "        )\n",
    "        self.init_bias()  # initialize bias\n",
    "\n",
    "    def init_bias(self):\n",
    "        for layer in self.net:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                nn.init.normal_(layer.weight, mean=0, std=0.01)\n",
    "                nn.init.constant_(layer.bias, 0)\n",
    "        # original paper = 1 for Conv2d layers 2nd, 4th, and 5th conv layers\n",
    "        nn.init.constant_(self.net[4].bias, 1)\n",
    "        nn.init.constant_(self.net[10].bias, 1)\n",
    "        nn.init.constant_(self.net[12].bias, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Pass the input through the net.\n",
    "        Args:\n",
    "            x (Tensor): input tensor\n",
    "        Returns:\n",
    "            output (Tensor): output tensor\n",
    "        \"\"\"\n",
    "        x = self.net(x)\n",
    "        x = x.view(-1, 256 * 6 * 6)  # reduce the dimensions for linear layer input\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "355ef7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = AlexNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4483edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand((1,3,227,227,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cef4282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n",
       "=====================================================================================================================================================================\n",
       "AlexNet                                  [1, 3, 227, 227]          [1, 1000]                 --                        --                        --\n",
       "├─Sequential: 1-1                        [1, 3, 227, 227]          [1, 256, 6, 6]            --                        --                        --\n",
       "│    └─Conv2d: 2-1                       [1, 3, 227, 227]          [1, 96, 55, 55]           34,944                    [11, 11]                  105,705,600\n",
       "│    └─ReLU: 2-2                         [1, 96, 55, 55]           [1, 96, 55, 55]           --                        --                        --\n",
       "│    └─LocalResponseNorm: 2-3            [1, 96, 55, 55]           [1, 96, 55, 55]           --                        --                        --\n",
       "│    └─MaxPool2d: 2-4                    [1, 96, 55, 55]           [1, 96, 27, 27]           --                        3                         --\n",
       "│    └─Conv2d: 2-5                       [1, 96, 27, 27]           [1, 256, 27, 27]          614,656                   [5, 5]                    448,084,224\n",
       "│    └─ReLU: 2-6                         [1, 256, 27, 27]          [1, 256, 27, 27]          --                        --                        --\n",
       "│    └─LocalResponseNorm: 2-7            [1, 256, 27, 27]          [1, 256, 27, 27]          --                        --                        --\n",
       "│    └─MaxPool2d: 2-8                    [1, 256, 27, 27]          [1, 256, 13, 13]          --                        3                         --\n",
       "│    └─Conv2d: 2-9                       [1, 256, 13, 13]          [1, 384, 13, 13]          885,120                   [3, 3]                    149,585,280\n",
       "│    └─ReLU: 2-10                        [1, 384, 13, 13]          [1, 384, 13, 13]          --                        --                        --\n",
       "│    └─Conv2d: 2-11                      [1, 384, 13, 13]          [1, 384, 13, 13]          1,327,488                 [3, 3]                    224,345,472\n",
       "│    └─ReLU: 2-12                        [1, 384, 13, 13]          [1, 384, 13, 13]          --                        --                        --\n",
       "│    └─Conv2d: 2-13                      [1, 384, 13, 13]          [1, 256, 13, 13]          884,992                   [3, 3]                    149,563,648\n",
       "│    └─ReLU: 2-14                        [1, 256, 13, 13]          [1, 256, 13, 13]          --                        --                        --\n",
       "│    └─MaxPool2d: 2-15                   [1, 256, 13, 13]          [1, 256, 6, 6]            --                        3                         --\n",
       "├─Sequential: 1-2                        [1, 9216]                 [1, 1000]                 --                        --                        --\n",
       "│    └─Dropout: 2-16                     [1, 9216]                 [1, 9216]                 --                        --                        --\n",
       "│    └─Linear: 2-17                      [1, 9216]                 [1, 4096]                 37,752,832                --                        37,752,832\n",
       "│    └─ReLU: 2-18                        [1, 4096]                 [1, 4096]                 --                        --                        --\n",
       "│    └─Dropout: 2-19                     [1, 4096]                 [1, 4096]                 --                        --                        --\n",
       "│    └─Linear: 2-20                      [1, 4096]                 [1, 4096]                 16,781,312                --                        16,781,312\n",
       "│    └─ReLU: 2-21                        [1, 4096]                 [1, 4096]                 --                        --                        --\n",
       "│    └─Linear: 2-22                      [1, 4096]                 [1, 1000]                 4,097,000                 --                        4,097,000\n",
       "=====================================================================================================================================================================\n",
       "Total params: 62,378,344\n",
       "Trainable params: 62,378,344\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.14\n",
       "=====================================================================================================================================================================\n",
       "Input size (MB): 0.62\n",
       "Forward/backward pass size (MB): 5.27\n",
       "Params size (MB): 249.51\n",
       "Estimated Total Size (MB): 255.41\n",
       "====================================================================================================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(x, (3, 227, 227), batch_dim = 0, col_names = (\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"), verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "036ec850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "979ef801",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0b1cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5870f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bd17400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3322,  0.3746, -0.3970, -0.2149,  0.2129,  0.3408, -0.5146,  0.1952,\n",
       "          0.0072,  0.0812,  0.1134, -0.0767, -0.2035,  0.0347, -0.3271,  0.6199,\n",
       "          0.0733, -0.0651, -0.0741,  0.0135,  0.1648,  0.1244, -0.1607,  0.1695,\n",
       "          0.5059,  0.0437, -0.1140,  0.1597, -0.0088, -0.1058,  0.2961,  0.0657,\n",
       "         -0.0387,  0.1882, -0.0455,  0.1156, -0.0224, -0.0634, -0.0079, -0.2055,\n",
       "          0.2123,  0.3814,  0.0867,  0.2091,  0.2246,  0.0856,  0.0369, -0.3703,\n",
       "         -0.0762,  0.0707, -0.2888,  0.0456,  0.0623,  0.2675,  0.0282, -0.2014,\n",
       "          0.2006,  0.5669, -0.0159, -0.0487, -0.2790, -0.2594, -0.2636,  0.1351,\n",
       "          0.3174, -0.1233,  0.2518, -0.3649,  0.1588, -0.1956, -0.1571, -0.0717,\n",
       "          0.0200,  0.5230, -0.0748, -0.0034, -0.2204, -0.5263, -0.2485, -0.3797,\n",
       "         -0.1951, -0.0783,  0.0204, -0.1781,  0.3133, -0.0224,  0.6893, -0.4046,\n",
       "         -0.2345,  0.1565,  0.1917,  0.1060, -0.0135, -0.1921, -0.0197, -0.0428,\n",
       "          0.0031,  0.0819,  0.0108,  0.0362, -0.1402,  0.0749, -0.2978,  0.1690,\n",
       "          0.0312,  0.2894, -0.0819,  0.0050, -0.2865,  0.4033,  0.2359, -0.2299,\n",
       "         -0.2518,  0.0487,  0.2867,  0.3358,  0.0128,  0.2066, -0.1289, -0.2631,\n",
       "         -0.1056,  0.1287, -0.0841, -0.1673,  0.2367, -0.3526,  0.2573, -0.2545,\n",
       "         -0.0032, -0.0176,  0.2241,  0.1244, -0.1897, -0.2041,  0.5436,  0.1470,\n",
       "          0.0231, -0.3242,  0.0062, -0.0411,  0.3854, -0.0453,  0.1013, -0.0533,\n",
       "         -0.1121,  0.1769,  0.0980,  0.3395, -0.1112, -0.1784, -0.0359, -0.0426,\n",
       "          0.2185, -0.1050,  0.2316,  0.3029,  0.0701,  0.0178, -0.1677, -0.4426,\n",
       "         -0.0427,  0.0975,  0.5108,  0.1800,  0.0599,  0.2878, -0.2202,  0.0326,\n",
       "          0.1793, -0.3737, -0.1470, -0.2880,  0.1066,  0.0640, -0.0384,  0.1674,\n",
       "          0.3036,  0.1229, -0.3954,  0.3398, -0.2395,  0.0056,  0.1636,  0.1260,\n",
       "          0.1920,  0.1408,  0.0089, -0.0446,  0.0492, -0.0201,  0.2808, -0.0878,\n",
       "          0.0593,  0.2198,  0.0349,  0.3238, -0.1872,  0.3973,  0.0664, -0.1298,\n",
       "          0.1860, -0.0252, -0.8548, -0.0048, -0.0374,  0.3224, -0.0516, -0.4782,\n",
       "          0.3106,  0.1310,  0.4625,  0.1330, -0.1965, -0.2877, -0.1749,  0.0924,\n",
       "         -0.4322,  0.1001,  0.1120,  0.2843, -0.1740, -0.5609, -0.1392, -0.1132,\n",
       "          0.0523,  0.0765,  0.0700, -0.6828,  0.0266, -0.1250,  0.0515, -0.0342,\n",
       "          0.0174, -0.0084, -0.1759,  0.1208, -0.4142, -0.1367,  0.3106, -0.1957,\n",
       "         -0.1842,  0.5096,  0.3391,  0.2044, -0.1589,  0.0595, -0.0250, -0.2584,\n",
       "         -0.0526, -0.3472, -0.1885, -0.0790, -0.1221, -0.0676, -0.2035, -0.1709,\n",
       "         -0.1876,  0.2409, -0.1425, -0.2962, -0.0074,  0.2950, -0.0499, -0.1906,\n",
       "         -0.2297,  0.1733,  0.0408, -0.1530,  0.1732, -0.3277, -0.3774, -0.1792,\n",
       "          0.1435,  0.0644, -0.1380, -0.2509,  0.0198, -0.0505, -0.2324, -0.3812,\n",
       "         -0.2886, -0.0742, -0.3822,  0.1114,  0.0379, -0.4072,  0.3539, -0.3821,\n",
       "          0.1550, -0.3576, -0.2326,  0.0577,  0.2350,  0.5205, -0.3237,  0.0523,\n",
       "          0.2602,  0.1657,  0.4421,  0.1674, -0.0919, -0.2040,  0.0856,  0.2527,\n",
       "          0.1680, -0.1159, -0.1349, -0.0436,  0.2023,  0.6567,  0.1886, -0.0880,\n",
       "         -0.0243,  0.0225,  0.2363, -0.2261, -0.1028, -0.1619,  0.0653, -0.1513,\n",
       "         -0.4110, -0.0920,  0.3741, -0.2770,  0.1679, -0.1873,  0.0623,  0.0780,\n",
       "          0.0723,  0.3854,  0.2690, -0.0355, -0.0249,  0.0387, -0.3790,  0.0328,\n",
       "         -0.1525,  0.0173,  0.0275, -0.3669,  0.1395,  0.4121,  0.5485, -0.3431,\n",
       "         -0.3098,  0.0537, -0.0050, -0.1295, -0.2392, -0.6856,  0.0413, -0.1192,\n",
       "         -0.1572,  0.3511, -0.0181, -0.1156,  0.2547, -0.0804,  0.2229,  0.0855,\n",
       "          0.0196, -0.1979,  0.2907,  0.0396,  0.0062,  0.1079,  0.2430, -0.0874,\n",
       "         -0.2713, -0.0523,  0.1538,  0.0093,  0.1572,  0.1653,  0.1153, -0.2947,\n",
       "          0.3102,  0.2315,  0.2135, -0.1049, -0.2042, -0.0135, -0.0837, -0.3575,\n",
       "          0.2794, -0.1399,  0.1146,  0.0493, -0.0682, -0.4033,  0.2375,  0.1308,\n",
       "          0.0756,  0.1687,  0.3097, -0.0926,  0.2754,  0.1665, -0.5333, -0.1898,\n",
       "         -0.1997, -0.1990, -0.2145,  0.3470, -0.2188,  0.1731, -0.2716, -0.0036,\n",
       "          0.1954,  0.2381, -0.0882, -0.0310, -0.0293, -0.1881, -0.1968,  0.0159,\n",
       "          0.4312, -0.0028, -0.2747,  0.2939,  0.1063, -0.0613,  0.1223, -0.1675,\n",
       "          0.2197,  0.0862,  0.0235, -0.0455,  0.0734, -0.2989,  0.4754,  0.3013,\n",
       "         -0.0894,  0.2340,  0.1178,  0.3028, -0.0674, -0.1188,  0.1723, -0.1907,\n",
       "         -0.0517,  0.4687, -0.1143, -0.1057, -0.1624, -0.0848,  0.0457, -0.2705,\n",
       "         -0.0659, -0.1796,  0.4157,  0.0546, -0.0425,  0.2597,  0.1277, -0.0111,\n",
       "         -0.1546,  0.2623, -0.0034, -0.2172, -0.1249,  0.0801,  0.0175, -0.0016,\n",
       "          0.2067, -0.0532,  0.1286, -0.1980,  0.2641, -0.0348,  0.0056,  0.1701,\n",
       "         -0.1578, -0.0166, -0.1828, -0.0483, -0.6755, -0.4584, -0.0918, -0.1519,\n",
       "         -0.0790,  0.4844, -0.0633,  0.1474, -0.0932, -0.2276, -0.0020, -0.1274,\n",
       "          0.2223, -0.1039,  0.1606, -0.0709, -0.2365, -0.2991,  0.0188, -0.4262,\n",
       "          0.3875,  0.4394,  0.0615, -0.1399, -0.2159, -0.1984, -0.1317, -0.3528,\n",
       "          0.3235,  0.1832,  0.0946, -0.0666,  0.0338,  0.1286, -0.0063, -0.1685,\n",
       "         -0.0692, -0.4896,  0.1936,  0.2010, -0.0156, -0.1573, -0.0011,  0.0489,\n",
       "          0.6206,  0.1324,  0.0279,  0.0030,  0.1421, -0.2525,  0.0063, -0.1907,\n",
       "         -0.4501, -0.2265, -0.1800, -0.2974,  0.3001, -0.0331, -0.0170,  0.0193,\n",
       "          0.1586,  0.2413,  0.2350, -0.0333, -0.2298,  0.0783,  0.4059,  0.3160,\n",
       "          0.0637,  0.0557, -0.3254, -0.0873, -0.1363, -0.0743, -0.4200, -0.3154,\n",
       "         -0.4287,  0.4462, -0.5488,  0.1169, -0.1014,  0.1438, -0.2228,  0.2894,\n",
       "          0.1105, -0.3481,  0.3724, -0.1755,  0.2711, -0.0895, -0.1693,  0.0620,\n",
       "         -0.2293,  0.1709, -0.1830,  0.2672,  0.0175,  0.2842, -0.1989, -0.1074,\n",
       "          0.3521,  0.1776,  0.0551,  0.0780, -0.0531,  0.3385, -0.1424, -0.1634,\n",
       "         -0.1646, -0.1184,  0.0147, -0.3442,  0.0201, -0.1338, -0.2887,  0.0846,\n",
       "          0.3856, -0.0024,  0.0586, -0.0615, -0.1005,  0.1552,  0.2761,  0.1801,\n",
       "         -0.0809, -0.0705, -0.5256, -0.1424, -0.1614, -0.0912,  0.2611,  0.5766,\n",
       "         -0.3859, -0.0867, -0.1737,  0.1179,  0.0293,  0.0025, -0.0932, -0.1907,\n",
       "          0.0034, -0.0820,  0.2600,  0.2778,  0.0348,  0.3217, -0.1361,  0.0780,\n",
       "          0.0297,  0.0717, -0.1485,  0.4315,  0.0566, -0.2425, -0.3386, -0.0607,\n",
       "         -0.0115,  0.0910, -0.4138,  0.1085, -0.1426, -0.2420,  0.0485, -0.3897,\n",
       "          0.1931, -0.1783,  0.1311, -0.1346,  0.1224, -0.2552, -0.2798,  0.0581,\n",
       "          0.2056,  0.2240,  0.1200, -0.0497, -0.2108,  0.1180, -0.0797, -0.1310,\n",
       "          0.3563,  0.2896,  0.1187, -0.0898,  0.1387, -0.6204, -0.3311, -0.4002,\n",
       "          0.0107,  0.2273,  0.0025,  0.3710, -0.0438,  0.1099,  0.3192,  0.1087,\n",
       "         -0.0351,  0.2624, -0.2459, -0.0469, -0.0635, -0.0048, -0.2192,  0.1227,\n",
       "         -0.0656, -0.0541, -0.0628,  0.4800, -0.3445, -0.0480,  0.0145,  0.1192,\n",
       "         -0.1964, -0.0634, -0.1657,  0.3545, -0.1385,  0.0059, -0.2420, -0.1583,\n",
       "          0.3630,  0.0465,  0.5300, -0.4180, -0.0045,  0.3385,  0.0770, -0.5329,\n",
       "         -0.0316,  0.0234, -0.2685,  0.0715, -0.0696,  0.2188,  0.0650,  0.1132,\n",
       "          0.1552,  0.1780, -0.2473,  0.0982,  0.5983, -0.0799,  0.3243, -0.0739,\n",
       "          0.0067,  0.1899,  0.4261, -0.0703, -0.3804,  0.0525, -0.3737, -0.2325,\n",
       "         -0.0090, -0.3313,  0.5331, -0.1354, -0.1139, -0.3213,  0.3605,  0.5404,\n",
       "          0.0786,  0.1360, -0.0550, -0.2989,  0.0132, -0.0307, -0.1316, -0.1738,\n",
       "         -0.0640,  0.0104, -0.2104, -0.2506,  0.4590, -0.6670, -0.0110, -0.0283,\n",
       "          0.0838,  0.1262, -0.1704, -0.0307, -0.0830,  0.1072,  0.1109,  0.0246,\n",
       "          0.0535, -0.2417, -0.2234, -0.2931,  0.1111,  0.0820,  0.2609,  0.0161,\n",
       "         -0.0105, -0.0014,  0.0604,  0.4547,  0.1063, -0.0530, -0.1898,  0.2629,\n",
       "         -0.1165,  0.4200,  0.5960, -0.2889,  0.1341,  0.2344,  0.0861, -0.0077,\n",
       "          0.5167, -0.1782,  0.3871,  0.5618, -0.1637, -0.2784, -0.0476, -0.0411,\n",
       "          0.0389,  0.2268, -0.1199,  0.2326,  0.2322,  0.1691,  0.0202,  0.0160,\n",
       "         -0.0500, -0.2553,  0.0475,  0.2278, -0.2334,  0.0166, -0.2434,  0.0254,\n",
       "          0.1806,  0.0574, -0.2109,  0.0009,  0.7908,  0.2264,  0.0741,  0.1769,\n",
       "         -0.0377, -0.3230, -0.1258, -0.0827,  0.1606, -0.3131, -0.4361, -0.2183,\n",
       "         -0.1504, -0.0477,  0.0976,  0.0533, -0.4407, -0.1011, -0.0549, -0.4198,\n",
       "         -0.0330,  0.3824, -0.0996,  0.1646,  0.1449,  0.1683,  0.0855,  0.0355,\n",
       "         -0.0676, -0.0568, -0.0798,  0.0873, -0.0064,  0.3222,  0.0439, -0.2586,\n",
       "          0.0127, -0.4936,  0.2035, -0.0351, -0.0392, -0.0696,  0.3476,  0.0469,\n",
       "          0.1165, -0.0514,  0.0287,  0.1350,  0.1386,  0.2980,  0.0810,  0.0793,\n",
       "         -0.2202, -0.2515,  0.4483, -0.4876,  0.0073,  0.1083,  0.1289,  0.2669,\n",
       "         -0.0185,  0.5054, -0.0645, -0.0808,  0.3623,  0.0091, -0.2033,  0.4927,\n",
       "         -0.2403, -0.3611,  0.0749, -0.0354,  0.0275, -0.0156,  0.1729, -0.0726,\n",
       "          0.0324, -0.2164,  0.2191,  0.2542,  0.0092, -0.1090,  0.1062,  0.0773,\n",
       "          0.0889, -0.0973, -0.2161, -0.1568, -0.0792, -0.0676, -0.4658,  0.2807,\n",
       "          0.1603,  0.5828,  0.2132,  0.2585,  0.1534, -0.0611,  0.1207, -0.1032,\n",
       "         -0.0689,  0.3564,  0.3397,  0.1396, -0.0047, -0.2483,  0.1617, -0.0432,\n",
       "          0.3058,  0.2204,  0.1532, -0.0136, -0.1773,  0.0883, -0.1459, -0.0704,\n",
       "         -0.1371,  0.0973,  0.1509,  0.1886, -0.2021, -0.4933, -0.1228,  0.0918,\n",
       "          0.2423,  0.2641,  0.0622, -0.0545,  0.0396,  0.2796,  0.4076,  0.2332,\n",
       "         -0.2997, -0.2654,  0.0348,  0.0283, -0.2321,  0.1808, -0.6487, -0.5625,\n",
       "         -0.1549,  0.0204, -0.1600,  0.2982,  0.2217, -0.3643,  0.2694,  0.2269,\n",
       "         -0.2381, -0.0768,  0.3662, -0.1229, -0.4525, -0.0034, -0.0167,  0.1057,\n",
       "         -0.2799,  0.0620, -0.2013, -0.2128, -0.0718, -0.0331,  0.0075, -0.1856,\n",
       "          0.3245, -0.4227,  0.1474,  0.0709, -0.4361,  0.0558, -0.2309,  0.1627,\n",
       "          0.1978, -0.3521,  0.0676,  0.0366,  0.0042, -0.1189, -0.3753,  0.5274,\n",
       "          0.1117, -0.0604,  0.1136,  0.1342,  0.3412, -0.2995,  0.0444,  0.1564]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5fe092a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1000])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c93d9903",
   "metadata": {},
   "outputs": [],
   "source": [
    "##copied from \"https://github.com/chongwar/vgg16-pytorch/blob/master/vgg16.py\"\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "\n",
    "    def __init__(self, NUM_CLASSES):\n",
    "        super(VGG16, self).__init__()\n",
    "\n",
    "        # calculate same padding:\n",
    "        # (w - k + 2*p)/s + 1 = o\n",
    "        # => p = (s(o-1) - w + k)/2\n",
    "\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=(3, 3),\n",
    "                      stride=(1, 1),\n",
    "                      # (1(32-1)- 32 + 3)/2 = 1\n",
    "                      padding=1),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=(3, 3),\n",
    "                      stride=(1, 1),\n",
    "                      padding=1),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                         stride=(2, 2))\n",
    "        )\n",
    "\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64,\n",
    "                      out_channels=128,\n",
    "                      kernel_size=(3, 3),\n",
    "                      stride=(1, 1),\n",
    "                      padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128,\n",
    "                      out_channels=128,\n",
    "                      kernel_size=(3, 3),\n",
    "                      stride=(1, 1),\n",
    "                      padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                         stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128,\n",
    "                      out_channels=256,\n",
    "                      kernel_size=(3, 3),\n",
    "                      stride=(1, 1),\n",
    "                      padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256,\n",
    "                      out_channels=256,\n",
    "                      kernel_size=(3, 3),\n",
    "                      stride=(1, 1),\n",
    "                      padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256,\n",
    "                      out_channels=256,\n",
    "                      kernel_size=(3, 3),\n",
    "                      stride=(1, 1),\n",
    "                      padding=1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                         stride=(2, 2))\n",
    "        )\n",
    "\n",
    "        self.block_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256,\n",
    "                      out_channels=512,\n",
    "                      kernel_size=(3, 3),\n",
    "                      stride=(1, 1),\n",
    "                      padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512,\n",
    "                      out_channels=512,\n",
    "                      kernel_size=(3, 3),\n",
    "                      stride=(1, 1),\n",
    "                      padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512,\n",
    "                      out_channels=512,\n",
    "                      kernel_size=(3, 3),\n",
    "                      stride=(1, 1),\n",
    "                      padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                         stride=(2, 2))\n",
    "        )\n",
    "\n",
    "        self.block_5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512,\n",
    "                      out_channels=512,\n",
    "                      kernel_size=(3, 3),\n",
    "                      stride=(1, 1),\n",
    "                      padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512,\n",
    "                      out_channels=512,\n",
    "                      kernel_size=(3, 3),\n",
    "                      stride=(1, 1),\n",
    "                      padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512,\n",
    "                      out_channels=512,\n",
    "                      kernel_size=(3, 3),\n",
    "                      stride=(1, 1),\n",
    "                      padding=1),\n",
    "            #nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                         stride=(2, 2))\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 4096),\n",
    "            nn.ReLU(True),\n",
    "            #nn.Dropout(p=0.65),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            #nn.Dropout(p=0.65),\n",
    "            nn.Linear(4096, NUM_CLASSES),\n",
    "        )\n",
    "\n",
    "        #for m in self.modules():\n",
    "        #    if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "        #        nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "#                 nn.init.xavier_normal_(m.weight)\n",
    "        #        if m.bias is not None:\n",
    "        #            m.bias.detach().zero_()\n",
    "\n",
    "        # self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = self.block_4(x)\n",
    "        x = self.block_5(x)\n",
    "        # x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        # probas = nn.Softmax(logits)\n",
    "        return probas\n",
    "        # return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1396c98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "import torchinfo\n",
    "model = VGG16(NUM_CLASSES)\n",
    "print(NUM_CLASSES)\n",
    "#torchinfo.summary(model, (3, 224, 224), batch_dim = 0, col_names = (\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"), verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c068ed2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Sequential: 1, Conv2d: 2, ReLU: 2, Conv2d: 2, ReLU: 2, MaxPool2d: 2, Sequential: 1, Conv2d: 2, ReLU: 2, Conv2d: 2, ReLU: 2, MaxPool2d: 2, Sequential: 1, Conv2d: 2, ReLU: 2, Conv2d: 2, ReLU: 2, Conv2d: 2, ReLU: 2, MaxPool2d: 2, Sequential: 1, Conv2d: 2, ReLU: 2, Conv2d: 2, BatchNorm2d: 2, ReLU: 2, Conv2d: 2, ReLU: 2, MaxPool2d: 2, Sequential: 1, Conv2d: 2, ReLU: 2, Conv2d: 2, ReLU: 2, Conv2d: 2, ReLU: 2, MaxPool2d: 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/SafeFBDC/github/sgx4ml-python/venv/lib/python3.9/site-packages/torchinfo/torchinfo.py:287\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 287\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/SafeFBDC/github/sgx4ml-python/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1148\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1148\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[0;32mIn [23], line 157\u001b[0m, in \u001b[0;36mVGG16.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    156\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 157\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m probas \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/SafeFBDC/github/sgx4ml-python/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1148\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1148\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/SafeFBDC/github/sgx4ml-python/venv/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/SafeFBDC/github/sgx4ml-python/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1148\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1148\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/SafeFBDC/github/sgx4ml-python/venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x25088 and 512x4096)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torchinfo\u001b[38;5;241m.\u001b[39msummary(model, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m), batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, col_names \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_size\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_size\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_params\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel_size\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmult_adds\u001b[39m\u001b[38;5;124m\"\u001b[39m), verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/SafeFBDC/github/sgx4ml-python/venv/lib/python3.9/site-packages/torchinfo/torchinfo.py:217\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m validate_user_params(\n\u001b[1;32m    211\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    212\u001b[0m )\n\u001b[1;32m    214\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[1;32m    215\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[1;32m    216\u001b[0m )\n\u001b[0;32m--> 217\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[1;32m    221\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[1;32m    222\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[1;32m    223\u001b[0m )\n",
      "File \u001b[0;32m~/SafeFBDC/github/sgx4ml-python/venv/lib/python3.9/site-packages/torchinfo/torchinfo.py:296\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    295\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Sequential: 1, Conv2d: 2, ReLU: 2, Conv2d: 2, ReLU: 2, MaxPool2d: 2, Sequential: 1, Conv2d: 2, ReLU: 2, Conv2d: 2, ReLU: 2, MaxPool2d: 2, Sequential: 1, Conv2d: 2, ReLU: 2, Conv2d: 2, ReLU: 2, Conv2d: 2, ReLU: 2, MaxPool2d: 2, Sequential: 1, Conv2d: 2, ReLU: 2, Conv2d: 2, BatchNorm2d: 2, ReLU: 2, Conv2d: 2, ReLU: 2, MaxPool2d: 2, Sequential: 1, Conv2d: 2, ReLU: 2, Conv2d: 2, ReLU: 2, Conv2d: 2, ReLU: 2, MaxPool2d: 2]"
     ]
    }
   ],
   "source": [
    "torchinfo.summary(model, (3, 224, 224), batch_dim = 0, col_names = (\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"), verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0293f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard PyTorch implementation of VGG. Pretrained imagenet model is used.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.features = nn.Sequential(\n",
    "            # conv1\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, return_indices=True),\n",
    "            \n",
    "            # conv2\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, return_indices=True),\n",
    "\n",
    "            # conv3\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, return_indices=True),\n",
    "\n",
    "            # conv4\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, return_indices=True),\n",
    "\n",
    "            # conv5\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 1000)\n",
    "        )\n",
    "\n",
    "        # We need these for MaxUnpool operation\n",
    "        self.conv_layer_indices = [0, 2, 5, 7, 10, 12, 14, 17, 19, 21, 24, 26, 28]\n",
    "        \n",
    "        #self.feature_maps = OrderedDict()\n",
    "        #self.pool_locs = OrderedDict()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.features:\n",
    "            if isinstance(layer, nn.MaxPool2d):\n",
    "                x, location = layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        \n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "def get_vgg():\n",
    "    vgg = VGG()\n",
    "    temp = torchvision.models.vgg16(pretrained=True)\n",
    "    vgg.load_state_dict(temp.state_dict())\n",
    "    return vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25ae7f48",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torchvision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m get_vgg()\n",
      "Cell \u001b[0;32mIn [30], line 81\u001b[0m, in \u001b[0;36mget_vgg\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vgg\u001b[39m():\n\u001b[1;32m     80\u001b[0m     vgg \u001b[38;5;241m=\u001b[39m VGG()\n\u001b[0;32m---> 81\u001b[0m     temp \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mvgg16(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     82\u001b[0m     vgg\u001b[38;5;241m.\u001b[39mload_state_dict(temp\u001b[38;5;241m.\u001b[39mstate_dict())\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vgg\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"
     ]
    }
   ],
   "source": [
    "model = get_vgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "228a8c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/gagandeep/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /Users/gagandeep/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 528M/528M [00:04<00:00, 114MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f29a4a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n",
       "=====================================================================================================================================================================\n",
       "VGG                                      [1, 3, 224, 224]          [1, 1000]                 --                        --                        --\n",
       "├─Sequential: 1-1                        [1, 3, 224, 224]          [1, 512, 7, 7]            --                        --                        --\n",
       "│    └─Conv2d: 2-1                       [1, 3, 224, 224]          [1, 64, 224, 224]         1,792                     [3, 3]                    89,915,392\n",
       "│    └─ReLU: 2-2                         [1, 64, 224, 224]         [1, 64, 224, 224]         --                        --                        --\n",
       "│    └─Conv2d: 2-3                       [1, 64, 224, 224]         [1, 64, 224, 224]         36,928                    [3, 3]                    1,852,899,328\n",
       "│    └─ReLU: 2-4                         [1, 64, 224, 224]         [1, 64, 224, 224]         --                        --                        --\n",
       "│    └─MaxPool2d: 2-5                    [1, 64, 224, 224]         [1, 64, 112, 112]         --                        2                         --\n",
       "│    └─Conv2d: 2-6                       [1, 64, 112, 112]         [1, 128, 112, 112]        73,856                    [3, 3]                    926,449,664\n",
       "│    └─ReLU: 2-7                         [1, 128, 112, 112]        [1, 128, 112, 112]        --                        --                        --\n",
       "│    └─Conv2d: 2-8                       [1, 128, 112, 112]        [1, 128, 112, 112]        147,584                   [3, 3]                    1,851,293,696\n",
       "│    └─ReLU: 2-9                         [1, 128, 112, 112]        [1, 128, 112, 112]        --                        --                        --\n",
       "│    └─MaxPool2d: 2-10                   [1, 128, 112, 112]        [1, 128, 56, 56]          --                        2                         --\n",
       "│    └─Conv2d: 2-11                      [1, 128, 56, 56]          [1, 256, 56, 56]          295,168                   [3, 3]                    925,646,848\n",
       "│    └─ReLU: 2-12                        [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --                        --\n",
       "│    └─Conv2d: 2-13                      [1, 256, 56, 56]          [1, 256, 56, 56]          590,080                   [3, 3]                    1,850,490,880\n",
       "│    └─ReLU: 2-14                        [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --                        --\n",
       "│    └─Conv2d: 2-15                      [1, 256, 56, 56]          [1, 256, 56, 56]          590,080                   [3, 3]                    1,850,490,880\n",
       "│    └─ReLU: 2-16                        [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --                        --\n",
       "│    └─MaxPool2d: 2-17                   [1, 256, 56, 56]          [1, 256, 28, 28]          --                        2                         --\n",
       "│    └─Conv2d: 2-18                      [1, 256, 28, 28]          [1, 512, 28, 28]          1,180,160                 [3, 3]                    925,245,440\n",
       "│    └─ReLU: 2-19                        [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --                        --\n",
       "│    └─Conv2d: 2-20                      [1, 512, 28, 28]          [1, 512, 28, 28]          2,359,808                 [3, 3]                    1,850,089,472\n",
       "│    └─ReLU: 2-21                        [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --                        --\n",
       "│    └─Conv2d: 2-22                      [1, 512, 28, 28]          [1, 512, 28, 28]          2,359,808                 [3, 3]                    1,850,089,472\n",
       "│    └─ReLU: 2-23                        [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --                        --\n",
       "│    └─MaxPool2d: 2-24                   [1, 512, 28, 28]          [1, 512, 14, 14]          --                        2                         --\n",
       "│    └─Conv2d: 2-25                      [1, 512, 14, 14]          [1, 512, 14, 14]          2,359,808                 [3, 3]                    462,522,368\n",
       "│    └─ReLU: 2-26                        [1, 512, 14, 14]          [1, 512, 14, 14]          --                        --                        --\n",
       "│    └─Conv2d: 2-27                      [1, 512, 14, 14]          [1, 512, 14, 14]          2,359,808                 [3, 3]                    462,522,368\n",
       "│    └─ReLU: 2-28                        [1, 512, 14, 14]          [1, 512, 14, 14]          --                        --                        --\n",
       "│    └─Conv2d: 2-29                      [1, 512, 14, 14]          [1, 512, 14, 14]          2,359,808                 [3, 3]                    462,522,368\n",
       "│    └─ReLU: 2-30                        [1, 512, 14, 14]          [1, 512, 14, 14]          --                        --                        --\n",
       "│    └─MaxPool2d: 2-31                   [1, 512, 14, 14]          [1, 512, 7, 7]            --                        2                         --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --                        --\n",
       "├─Sequential: 1-3                        [1, 25088]                [1, 1000]                 --                        --                        --\n",
       "│    └─Linear: 2-32                      [1, 25088]                [1, 4096]                 102,764,544               --                        102,764,544\n",
       "│    └─ReLU: 2-33                        [1, 4096]                 [1, 4096]                 --                        --                        --\n",
       "│    └─Dropout: 2-34                     [1, 4096]                 [1, 4096]                 --                        --                        --\n",
       "│    └─Linear: 2-35                      [1, 4096]                 [1, 4096]                 16,781,312                --                        16,781,312\n",
       "│    └─ReLU: 2-36                        [1, 4096]                 [1, 4096]                 --                        --                        --\n",
       "│    └─Dropout: 2-37                     [1, 4096]                 [1, 4096]                 --                        --                        --\n",
       "│    └─Linear: 2-38                      [1, 4096]                 [1, 1000]                 4,097,000                 --                        4,097,000\n",
       "=====================================================================================================================================================================\n",
       "Total params: 138,357,544\n",
       "Trainable params: 138,357,544\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 15.48\n",
       "=====================================================================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 108.45\n",
       "Params size (MB): 553.43\n",
       "Estimated Total Size (MB): 662.49\n",
       "====================================================================================================================================================================="
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model, (3, 224, 224), batch_dim = 0, col_names = (\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"), verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90843e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagandeep/SafeFBDC/github/sgx4ml-python/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using cache found in /Users/gagandeep/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /Users/gagandeep/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 548M/548M [00:59<00:00, 9.69MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "845e584a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n",
       "=====================================================================================================================================================================\n",
       "VGG                                      [1, 3, 224, 224]          [1, 1000]                 --                        --                        --\n",
       "├─Sequential: 1-1                        [1, 3, 224, 224]          [1, 512, 7, 7]            --                        --                        --\n",
       "│    └─Conv2d: 2-1                       [1, 3, 224, 224]          [1, 64, 224, 224]         1,792                     [3, 3]                    89,915,392\n",
       "│    └─ReLU: 2-2                         [1, 64, 224, 224]         [1, 64, 224, 224]         --                        --                        --\n",
       "│    └─Conv2d: 2-3                       [1, 64, 224, 224]         [1, 64, 224, 224]         36,928                    [3, 3]                    1,852,899,328\n",
       "│    └─ReLU: 2-4                         [1, 64, 224, 224]         [1, 64, 224, 224]         --                        --                        --\n",
       "│    └─MaxPool2d: 2-5                    [1, 64, 224, 224]         [1, 64, 112, 112]         --                        2                         --\n",
       "│    └─Conv2d: 2-6                       [1, 64, 112, 112]         [1, 128, 112, 112]        73,856                    [3, 3]                    926,449,664\n",
       "│    └─ReLU: 2-7                         [1, 128, 112, 112]        [1, 128, 112, 112]        --                        --                        --\n",
       "│    └─Conv2d: 2-8                       [1, 128, 112, 112]        [1, 128, 112, 112]        147,584                   [3, 3]                    1,851,293,696\n",
       "│    └─ReLU: 2-9                         [1, 128, 112, 112]        [1, 128, 112, 112]        --                        --                        --\n",
       "│    └─MaxPool2d: 2-10                   [1, 128, 112, 112]        [1, 128, 56, 56]          --                        2                         --\n",
       "│    └─Conv2d: 2-11                      [1, 128, 56, 56]          [1, 256, 56, 56]          295,168                   [3, 3]                    925,646,848\n",
       "│    └─ReLU: 2-12                        [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --                        --\n",
       "│    └─Conv2d: 2-13                      [1, 256, 56, 56]          [1, 256, 56, 56]          590,080                   [3, 3]                    1,850,490,880\n",
       "│    └─ReLU: 2-14                        [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --                        --\n",
       "│    └─Conv2d: 2-15                      [1, 256, 56, 56]          [1, 256, 56, 56]          590,080                   [3, 3]                    1,850,490,880\n",
       "│    └─ReLU: 2-16                        [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --                        --\n",
       "│    └─Conv2d: 2-17                      [1, 256, 56, 56]          [1, 256, 56, 56]          590,080                   [3, 3]                    1,850,490,880\n",
       "│    └─ReLU: 2-18                        [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --                        --\n",
       "│    └─MaxPool2d: 2-19                   [1, 256, 56, 56]          [1, 256, 28, 28]          --                        2                         --\n",
       "│    └─Conv2d: 2-20                      [1, 256, 28, 28]          [1, 512, 28, 28]          1,180,160                 [3, 3]                    925,245,440\n",
       "│    └─ReLU: 2-21                        [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --                        --\n",
       "│    └─Conv2d: 2-22                      [1, 512, 28, 28]          [1, 512, 28, 28]          2,359,808                 [3, 3]                    1,850,089,472\n",
       "│    └─ReLU: 2-23                        [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --                        --\n",
       "│    └─Conv2d: 2-24                      [1, 512, 28, 28]          [1, 512, 28, 28]          2,359,808                 [3, 3]                    1,850,089,472\n",
       "│    └─ReLU: 2-25                        [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --                        --\n",
       "│    └─Conv2d: 2-26                      [1, 512, 28, 28]          [1, 512, 28, 28]          2,359,808                 [3, 3]                    1,850,089,472\n",
       "│    └─ReLU: 2-27                        [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --                        --\n",
       "│    └─MaxPool2d: 2-28                   [1, 512, 28, 28]          [1, 512, 14, 14]          --                        2                         --\n",
       "│    └─Conv2d: 2-29                      [1, 512, 14, 14]          [1, 512, 14, 14]          2,359,808                 [3, 3]                    462,522,368\n",
       "│    └─ReLU: 2-30                        [1, 512, 14, 14]          [1, 512, 14, 14]          --                        --                        --\n",
       "│    └─Conv2d: 2-31                      [1, 512, 14, 14]          [1, 512, 14, 14]          2,359,808                 [3, 3]                    462,522,368\n",
       "│    └─ReLU: 2-32                        [1, 512, 14, 14]          [1, 512, 14, 14]          --                        --                        --\n",
       "│    └─Conv2d: 2-33                      [1, 512, 14, 14]          [1, 512, 14, 14]          2,359,808                 [3, 3]                    462,522,368\n",
       "│    └─ReLU: 2-34                        [1, 512, 14, 14]          [1, 512, 14, 14]          --                        --                        --\n",
       "│    └─Conv2d: 2-35                      [1, 512, 14, 14]          [1, 512, 14, 14]          2,359,808                 [3, 3]                    462,522,368\n",
       "│    └─ReLU: 2-36                        [1, 512, 14, 14]          [1, 512, 14, 14]          --                        --                        --\n",
       "│    └─MaxPool2d: 2-37                   [1, 512, 14, 14]          [1, 512, 7, 7]            --                        2                         --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --                        --\n",
       "├─Sequential: 1-3                        [1, 25088]                [1, 1000]                 --                        --                        --\n",
       "│    └─Linear: 2-38                      [1, 25088]                [1, 4096]                 102,764,544               --                        102,764,544\n",
       "│    └─ReLU: 2-39                        [1, 4096]                 [1, 4096]                 --                        --                        --\n",
       "│    └─Dropout: 2-40                     [1, 4096]                 [1, 4096]                 --                        --                        --\n",
       "│    └─Linear: 2-41                      [1, 4096]                 [1, 4096]                 16,781,312                --                        16,781,312\n",
       "│    └─ReLU: 2-42                        [1, 4096]                 [1, 4096]                 --                        --                        --\n",
       "│    └─Dropout: 2-43                     [1, 4096]                 [1, 4096]                 --                        --                        --\n",
       "│    └─Linear: 2-44                      [1, 4096]                 [1, 1000]                 4,097,000                 --                        4,097,000\n",
       "=====================================================================================================================================================================\n",
       "Total params: 143,667,240\n",
       "Trainable params: 143,667,240\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 19.65\n",
       "=====================================================================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 118.89\n",
       "Params size (MB): 574.67\n",
       "Estimated Total Size (MB): 694.16\n",
       "====================================================================================================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(model, (3, 224, 224), batch_dim = 0, col_names = (\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"), verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7ea3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from CNN_FashionMNIST_model import CNN\n",
    "\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52faaa54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n",
       "=====================================================================================================================================================================\n",
       "CNN                                      [1, 1, 28, 28]            [1, 10]                   --                        --                        --\n",
       "├─Conv2d: 1-1                            [1, 1, 28, 28]            [1, 6, 24, 24]            156                       [5, 5]                    89,856\n",
       "├─Conv2d: 1-2                            [1, 6, 12, 12]            [1, 12, 8, 8]             1,812                     [5, 5]                    115,968\n",
       "├─Linear: 1-3                            [1, 192]                  [1, 120]                  23,160                    --                        23,160\n",
       "├─Linear: 1-4                            [1, 120]                  [1, 60]                   7,260                     --                        7,260\n",
       "├─Linear: 1-5                            [1, 60]                   [1, 10]                   610                       --                        610\n",
       "=====================================================================================================================================================================\n",
       "Total params: 32,998\n",
       "Trainable params: 32,998\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.24\n",
       "=====================================================================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.04\n",
       "Params size (MB): 0.13\n",
       "Estimated Total Size (MB): 0.17\n",
       "====================================================================================================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(model, (1, 28, 28), batch_dim = 0, col_names = (\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"), verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8bc434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
