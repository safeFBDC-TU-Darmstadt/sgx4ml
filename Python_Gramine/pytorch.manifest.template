# PyTorch manifest template

loader.entrypoint = "file:{{ gramine.libos }}"
libos.entrypoint = "{{ entrypoint }}"

loader.log_level = "{{ log_level }}"

loader.env.LD_LIBRARY_PATH = "/lib:/usr/lib:{{ arch_libdir }}:/usr/{{ arch_libdir }}"

# Restrict the maximum number of threads to prevent insufficient memory
# issue, observed on CentOS/RHEL.
loader.env.OMP_NUM_THREADS = { passthrough = true }

loader.insecure__use_cmdline_argv = true
# loader.insecure__use_host_env = true

loader.pal_internal_mem_size = "128M"

fs.mounts = [
  { uri = "file:{{ gramine.runtimedir() }}", path = "/lib" },
  { uri = "file:{{ arch_libdir }}", path = "{{ arch_libdir }}" },
  { uri = "file:/usr", path = "/usr" },
  { uri = "file:/etc", path = "/etc" },
  { uri = "file:{{ pillow_path }}", path = "{{ pillow_path }}" },

  { type = "tmpfs", path = "/tmp" },
]

# PyTorch loads its pre-trained models from here
# Add below uncommented line to fs.mounts array if you want to use torchvision.model.alexnet(pretrained=True)
# { type = "chroot", uri = "file:{{ env.HOME }}/.cache/torch", path = "{{ env.HOME }}/.cache/torch" }

sgx.nonpie_binary = true
sgx.enclave_size = "8G"
sgx.thread_num = 48

# sgx.file_check_policy = "allow_all_but_log"

sgx.trusted_files = [
# libraries and python dependencies
  "file:{{ gramine.libos }}",
  "file:{{ entrypoint }}",
  "file:{{ gramine.runtimedir() }}/",
  "file:{{ arch_libdir }}/",
  "file:/usr/{{ arch_libdir }}/",
  "file:{{ python.stdlib }}/",
  "file:{{ python.distlib }}/",
  "file:{{ pillow_path }}",
  # "file:{{ python.get_path('stdlib', vars={'installed_base': '/usr/local'}) }}/",

# Python executable files
  "file:Inference_exp_new.py",

#  NN models   
   "file:output/saved_cnn_model.pt",
   "file:output/saved_cnn_new_model.pt",
   "file:output/saved_large_mlp1_model.pt",
   "file:output/saved_large_mlp2_model.pt",
   "file:output/saved_mlp_model.pt",
   "file:output/saved_alexnet_model.pt",
   "file:output/saved_vgg16_model.pt",
   "file:output/saved_vgg19_model.pt",
   "file:output/saved_alexnet_simple.pt",

   "file:models/ALEXNET_model.py",
   "file:models/cnn_new.py",
   "file:models/Large_MLP1.py",
   "file:models/Large_MLP2.py",
   "file:models/CNN_FashionMNIST_model.py",
   "file:models/MLP_FashionMNIST_model.py",
   "file:models/ALEXNET_simple.py",
  # Uncomment line below if you want to use torchvision.model.alexnet(pretrained=True)
  # "file:{{ env.HOME }}/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth",
]

sgx.allowed_files = [
  "file:results"
]

# Gramine optionally provides patched OpenMP runtime library that runs faster
# inside SGX enclaves (execute `make -C LibOS gcc` to generate it). Uncomment
# the lines below to use the patched library. PyTorch's SGX perf overhead
# decreases on some workloads from 25% to 8% with this patched library. Note
# that we need to preload the library because PyTorch's distribution renames
# libgomp.so to smth like libgomp-7c85b1e2.so.1, so it's not just a matter of
# searching in the Gramine's Runtime path first, but a matter of intercepting
# OpenMP functions.
loader.env.LD_PRELOAD = "/lib/libgomp.so.1"
